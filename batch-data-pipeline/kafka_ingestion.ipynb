{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/snowflake/connector/options.py:96: UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<8.1.0,>=8.0.0; extra == \"pandas\"'\n",
      "  warn_incompatible_dep(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Kafka consumer ready and consumes messages'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from confluent_kafka import Consumer\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import snowflake.connector\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from statistics import mean\n",
    "load_dotenv()\n",
    "\n",
    "KAFKA_SERVER = os.getenv('KAFKA_SERVER')\n",
    "KAFKA_USERNAME=os.getenv('KAFKA_USERNAME')\n",
    "KAFKA_PASSWORD=os.getenv('KAFKA_PASSWORD')\n",
    "KAFKA_TOPIC_NAME = os.getenv('KAFKA_TOPIC_NAME')\n",
    "\n",
    "USER = os.environ.get('USER')\n",
    "ACCOUNT = os.environ.get('ACCOUNT')\n",
    "PASSWORD = os.environ.get('PASSWORD')\n",
    "WAREHOUSE= os.environ.get('WAREHOUSE')\n",
    "DATABASE= os.environ.get('DATABASE')\n",
    "SCHEMA= os.environ.get('SCHEMA')\n",
    "\n",
    "c = Consumer({\n",
    "    'bootstrap.servers': KAFKA_SERVER,\n",
    "    'group.id': f'deleton' +str(uuid.uuid1()),\n",
    "    'security.protocol': 'SASL_SSL',\n",
    "    'sasl.mechanisms': 'PLAIN',\n",
    "    'sasl.username': KAFKA_USERNAME,\n",
    "    'sasl.password': KAFKA_PASSWORD,\n",
    "    'session.timeout.ms': 6000,\n",
    "    'heartbeat.interval.ms': 1000,\n",
    "    'fetch.wait.max.ms': 6000,\n",
    "    'auto.offset.reset': 'latest',\n",
    "    'enable.auto.commit': 'false',\n",
    "    'max.poll.interval.ms': '86400000',\n",
    "    'topic.metadata.refresh.interval.ms': \"-1\",\n",
    "    \"client.id\": 'id-002-005',\n",
    "})\n",
    "\n",
    "c.subscribe([KAFKA_TOPIC_NAME])\n",
    "\"\"\"Kafka consumer ready and consumes messages\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_values_from_log(string):\n",
    "    regex=r'\\d+.?\\d+|\\d'\n",
    "    log_values = re.findall(regex,string)\n",
    "    return log_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_system_log():\n",
    "    while True:\n",
    "        kafka_message = c.poll(0.5)\n",
    "        if kafka_message is not None:\n",
    "            log = kafka_message.value().decode('utf-8')\n",
    "\n",
    "            if 'SYSTEM' in log:\n",
    "                return kafka_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_unix_to_date(unix_timestamp):\n",
    "    unix_timestamp /= 1000  #convert to seconds as unix timestamp is in milliseconds\n",
    "    converted_to_date = datetime.utcfromtimestamp(unix_timestamp) \n",
    "  \n",
    "    current_time = datetime.now()\n",
    "    if converted_to_date > current_time:\n",
    "        return 'N/A'\n",
    "\n",
    "    return converted_to_date.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_full_name(name):\n",
    "    name_list = name.split(' ')\n",
    "    titles = ['Mr','Mrs','Miss','Ms','Dr']\n",
    "\n",
    "    if name_list[0] in titles:\n",
    "        first_name = name_list[1]\n",
    "        try:\n",
    "            last_name = name_list[2]\n",
    "        except IndexError:\n",
    "            last_name = None\n",
    "\n",
    "    else:\n",
    "        first_name = name_list[0]\n",
    "        last_name = name_list[1]\n",
    "\n",
    "    return first_name,last_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(address_list):\n",
    "    flat_list = []\n",
    "\n",
    "    for element in address_list:\n",
    "        if type(element) is list:\n",
    "          \n",
    "            for item in element:\n",
    "                flat_list.append(item)\n",
    "        else:\n",
    "            flat_list.append(element)\n",
    "    return flat_list\n",
    "\n",
    "\n",
    "def split_address(address):\n",
    "    address_list = address.split(',')\n",
    "\n",
    "    if len(address_list) < 4:\n",
    "        address_list[0] = address_list[0].split(' ', 1) \n",
    "        address_list = flatten_list(address_list)\n",
    "\n",
    "    house_number = address_list[0]\n",
    "    street_name = address_list[1].title()\n",
    "    region = address_list[2].title()\n",
    "    postcode = address_list[3]\n",
    "\n",
    "    return house_number,street_name,region,postcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_user_data(user_dictionary):\n",
    "    \n",
    "    user_dictionary['account_create_date'] = convert_unix_to_date(user_dictionary['account_create_date'])\n",
    "    user_dictionary['date_of_birth'] = convert_unix_to_date(user_dictionary['date_of_birth'])\n",
    "\n",
    "    first_name,last_name = split_full_name(user_dictionary['name'])\n",
    "\n",
    "    user_dictionary['first_name'] = first_name\n",
    "    user_dictionary['last_name'] = last_name\n",
    "\n",
    "    house_number,street_name,region,postcode = split_address(user_dictionary['address'])\n",
    "\n",
    "    user_dictionary['house_number'] = house_number\n",
    "    user_dictionary['street_name'] = street_name\n",
    "    user_dictionary['region'] = region\n",
    "    user_dictionary['postcode'] = postcode\n",
    "    user_dictionary['gender'] = user_dictionary['gender'].title()\n",
    "\n",
    "    return user_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'connect to snowflake to make queries'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = snowflake.connector.connect(\n",
    "    user=USER,\n",
    "    password=PASSWORD,\n",
    "    account=ACCOUNT,\n",
    "    warehouse=WAREHOUSE,\n",
    "    database=DATABASE,\n",
    "    schema='ZOOKEEPERS_BATCH_PRODUCTION'\n",
    ")\n",
    "cs = conn.cursor()\n",
    "\"\"\"connect to snowflake to make queries\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wait_for_first_user = True #Wait for current user to finish, so can obtain all relevant information\n",
    "first_user_collected = False #Add check for first user so data is not sent to snowflake prematurely\n",
    "\n",
    "resistance_list = []\n",
    "power_list = []\n",
    "heart_rate_list = []\n",
    "rpm_list = []\n",
    "\n",
    "while True:\n",
    "    kafka_message = c.poll(0.5)\n",
    "\n",
    "    if wait_for_first_user:\n",
    "        kafka_message = wait_for_system_log()\n",
    "        wait_for_first_user = False\n",
    "\n",
    "\n",
    "    if kafka_message is not None: #exclude none values\n",
    "        log = kafka_message.value().decode('utf-8')\n",
    "\n",
    "\n",
    "        if 'SYSTEM' in log:\n",
    "            first_user_collected = True\n",
    "            \n",
    "            system_log = json.loads(log).get('log')\n",
    "            split_log = system_log.split(' mendoza v9: [SYSTEM] data = ')\n",
    "            begin_timestamp = split_log[0]\n",
    "            \n",
    "            dictionary_string = split_log[1][:-1]\n",
    "            user_dictionary = json.loads(dictionary_string)\n",
    "            \n",
    "            user_dictionary = clean_user_data(user_dictionary)\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "        elif 'INFO' in log: #only check for strings with INFO\n",
    "\n",
    "            values = json.loads(log)\n",
    "            new_log = values.get('log')\n",
    "         \n",
    "\n",
    "            if 'Ride' in new_log: #process strings with Ride info\n",
    "                new_log = new_log.split(' mendoza v9: [INFO]: Ride - ')\n",
    "               \n",
    "                log_values = extract_values_from_log(new_log[1])\n",
    "\n",
    "                duration = int(float(log_values[0]))\n",
    "                resistance_list.append(int(log_values[1]))\n",
    "         \n",
    "\n",
    "            elif 'Telemetry' in new_log:\n",
    "                new_log = new_log.split(' mendoza v9: [INFO]: Telemetry - ')\n",
    "               \n",
    "                log_values = extract_values_from_log(new_log[1])\n",
    "\n",
    "                heart_rate_list.append(int(log_values[0]))\n",
    "                rpm_list.append(int(log_values[1]))\n",
    "                power_list.append(round(float(log_values[2]),3))\n",
    "\n",
    "\n",
    "        elif '---' in log and first_user_collected: #New user is starting, so load collected data into snowflake\n",
    "            total_power = sum(power_list)\n",
    "            mean_power = mean(power_list)\n",
    "            mean_rpm = mean(rpm_list)\n",
    "            mean_heart_rate = mean(heart_rate_list)\n",
    "            mean_resistance = mean(resistance_list)\n",
    "\n",
    "            cs.execute(f\"\"\"INSERT INTO users(user_id,first_name,last_name,gender,date_of_birth,height_cm,weight_kg,house_name,street,region,postcode,email,account_created)\n",
    "            VALUES(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s) \n",
    "            ({user_dictionary['user_id']},{user_dictionary['first_name']},{user_dictionary['last_name']},{user_dictionary['gender']},{user_dictionary['date_of_birth']},\n",
    "            {user_dictionary['height_cm']},{user_dictionary['weight_kg']},{user_dictionary['house_name']},{user_dictionary['street']},{user_dictionary['region']},\n",
    "            {user_dictionary['postcode']},{user_dictionary['email']},{user_dictionary['account_created']})\n",
    "            \"\"\")\n",
    "            print('made insert into users')\n",
    "            cs.execute(f\"\"\"INSERT INTO rides(user_id,begin_timestamp,total_duration_sec,total_power,mean_power,mean_resistance,mean_heart_rate)\n",
    "            VALUES(%s,%s,%s,%s,%s,%s,%s)\n",
    "            ({user_dictionary['user_id']},{begin_timestamp},{duration},{total_power},{mean_power},{mean_resistance},{mean_heart_rate})\n",
    "            \n",
    "            \"\"\")\n",
    "            print('made insert into rides')\n",
    "            \n",
    "            \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs.execute('desc table rides').fetchmany(50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
