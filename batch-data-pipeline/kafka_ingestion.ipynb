{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Consumer\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import snowflake.connector\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from statistics import mean\n",
    "load_dotenv()\n",
    "\n",
    "KAFKA_SERVER = os.getenv('KAFKA_SERVER')\n",
    "KAFKA_USERNAME=os.getenv('KAFKA_USERNAME')\n",
    "KAFKA_PASSWORD=os.getenv('KAFKA_PASSWORD')\n",
    "KAFKA_TOPIC_NAME = os.getenv('KAFKA_TOPIC_NAME')\n",
    "\n",
    "USER = os.environ.get('USER')\n",
    "ACCOUNT = os.environ.get('ACCOUNT')\n",
    "PASSWORD = os.environ.get('PASSWORD')\n",
    "WAREHOUSE= os.environ.get('WAREHOUSE')\n",
    "DATABASE= os.environ.get('DATABASE')\n",
    "SCHEMA= os.environ.get('SCHEMA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subscribe_to_kafka_topic():\n",
    "    \"\"\"Produce a consumer that subscribes to the relevant Kafka topic\"\"\"\n",
    "    c = Consumer({\n",
    "    'bootstrap.servers': KAFKA_SERVER,\n",
    "    'group.id': f'deleton' + str(uuid.uuid1()),\n",
    "    'security.protocol': 'SASL_SSL',\n",
    "    'sasl.mechanisms': 'PLAIN',\n",
    "    'sasl.username': KAFKA_USERNAME,\n",
    "    'sasl.password': KAFKA_PASSWORD,\n",
    "    'session.timeout.ms': 6000,\n",
    "    'heartbeat.interval.ms': 1000,\n",
    "    'fetch.wait.max.ms': 6000,\n",
    "    'auto.offset.reset': 'latest',\n",
    "    'enable.auto.commit': 'false',\n",
    "    'max.poll.interval.ms': '86400000',\n",
    "    'topic.metadata.refresh.interval.ms': \"-1\",\n",
    "    \"client.id\": 'id-002-005',\n",
    "})\n",
    "\n",
    "    c.subscribe([KAFKA_TOPIC_NAME])\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_values_from_log(string):\n",
    "    \"\"\"Extract numerical values from Kafka log using regular expression\"\"\"\n",
    "    regexp = r'\\d+.?\\d+|\\d'\n",
    "    numerical_values = re.findall(regexp,string)\n",
    "    return numerical_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_system_log(c):\n",
    "    \"\"\"Waits for current user when starting script to finish their ride, as their user data is not retrievable\"\"\"\n",
    "    while True:\n",
    "        kafka_message = c.poll(0.5)\n",
    "\n",
    "        if kafka_message is not None:\n",
    "            kafka_log = kafka_message.value().decode('utf-8')\n",
    "\n",
    "            if 'SYSTEM' in kafka_log:\n",
    "                return kafka_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_unix_to_date(unix_timestamp):\n",
    "    \"\"\"Converts unix timestamp to datetime\"\"\"\n",
    "    unix_timestamp /= 1000  #convert to seconds as unix timestamp is in milliseconds\n",
    "    converted_to_date = datetime.utcfromtimestamp(unix_timestamp).strftime('%Y-%m-%d')\n",
    " \n",
    "    return converted_to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_full_name(name):\n",
    "    \"\"\"Split full name based on various conditions, such as if they have a title or not, checks to see if they have a last name\"\"\"\n",
    "    name_list = name.split(' ')\n",
    "    titles = ['Mr','Mrs','Miss','Ms','Dr']\n",
    "\n",
    "    if name_list[0] in titles: #Exclude user titles from snowflake\n",
    "        first_name = name_list[1]\n",
    "\n",
    "        try:\n",
    "            last_name = name_list[2]\n",
    "\n",
    "        except IndexError: #Catch index error incase user did not give lastname\n",
    "            last_name = None\n",
    "\n",
    "    else:\n",
    "        first_name = name_list[0]\n",
    "        last_name = name_list[1]\n",
    "\n",
    "    return first_name,last_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(address_list):\n",
    "    \"\"\"Expands sublists present in lists, which is a consequence of splitting addresses\"\"\"\n",
    "    flat_list = []\n",
    "\n",
    "    for element in address_list:\n",
    "        if type(element) is list:\n",
    "          \n",
    "            for item in element:\n",
    "                flat_list.append(item)\n",
    "        else:\n",
    "            flat_list.append(element)\n",
    "    return flat_list\n",
    "\n",
    "\n",
    "def split_address(address):\n",
    "    \"\"\"Splits address based on various conditions, such as if they have whitespace or commas, or how many elements they have\"\"\"\n",
    "    address_list = address.split(',')\n",
    "\n",
    "    if len(address_list) < 4:\n",
    "        address_list[0] = address_list[0].split(' ', 1) \n",
    "        address_list = flatten_list(address_list)\n",
    "\n",
    "    house_number = address_list[0]\n",
    "    street_name = address_list[1].title()\n",
    "    region = address_list[2].title()\n",
    "    postcode = address_list[3]\n",
    "\n",
    "    return house_number,street_name,region,postcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_user_data(user_dictionary):\n",
    "    \"\"\"Clean user data by converting timestamps, obtaining first and lastname, and splitting address field\"\"\"\n",
    "    user_dictionary['account_create_date'] = convert_unix_to_date(user_dictionary['account_create_date'])\n",
    "    user_dictionary['date_of_birth'] = convert_unix_to_date(user_dictionary['date_of_birth'])\n",
    "\n",
    "    first_name,last_name = split_full_name(user_dictionary['name'])\n",
    "\n",
    "    user_dictionary['first_name'] = first_name\n",
    "    user_dictionary['last_name'] = last_name\n",
    "\n",
    "    house_number,street_name,region,postcode = split_address(user_dictionary['address'])\n",
    "\n",
    "    user_dictionary['house_number'] = house_number\n",
    "    user_dictionary['street_name'] = street_name\n",
    "    user_dictionary['region'] = region\n",
    "    user_dictionary['postcode'] = postcode\n",
    "    user_dictionary['gender'] = user_dictionary['gender'].title()\n",
    "\n",
    "    return user_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'connect to snowflake to make queries'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"connect to snowflake to make queries\"\"\"\n",
    "conn = snowflake.connector.connect(\n",
    "    user=USER,\n",
    "    password=PASSWORD,\n",
    "    account=ACCOUNT,\n",
    "    warehouse=WAREHOUSE,\n",
    "    database=DATABASE,\n",
    "    schema='ZOOKEEPERS_BATCH_PRODUCTION'\n",
    ")\n",
    "cs = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made insert into users\n",
      "made insert into rides\n",
      "made insert into users\n",
      "made insert into rides\n",
      "made insert into users\n",
      "made insert into rides\n"
     ]
    }
   ],
   "source": [
    "wait_for_first_user = True #Wait for current user to finish, so can obtain all relevant information\n",
    "first_user_collected = False #Add check for first user so data is not sent to snowflake prematurely\n",
    "\n",
    "resistance_list = []\n",
    "power_list = []\n",
    "heart_rate_list = []\n",
    "rpm_list = []\n",
    "\n",
    "c = subscribe_to_kafka_topic()\n",
    "\n",
    "while True:\n",
    "    \n",
    "    kafka_message = c.poll(0.5)\n",
    "\n",
    "    if wait_for_first_user:\n",
    "        kafka_message = wait_for_system_log(c)\n",
    "        wait_for_first_user = False\n",
    "\n",
    "\n",
    "    if kafka_message is not None: #exclude none values\n",
    "        log = kafka_message.value().decode('utf-8')\n",
    "\n",
    "\n",
    "        if 'SYSTEM' in log:\n",
    "            first_user_collected = True\n",
    "            \n",
    "            system_log = json.loads(log).get('log')\n",
    "            split_log = system_log.split(' mendoza v9: [SYSTEM] data = ')\n",
    "            begin_timestamp = split_log[0][:-7] #remove milliseconds from timestamp for snowflake compatability\n",
    "            \n",
    "            dictionary_string = split_log[1][:-1]\n",
    "            user_dictionary = json.loads(dictionary_string)\n",
    "            \n",
    "            user_dictionary = clean_user_data(user_dictionary)\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "        elif 'INFO' in log: #only check for strings with INFO\n",
    "\n",
    "            values = json.loads(log)\n",
    "            new_log = values.get('log')\n",
    "         \n",
    "\n",
    "            if 'Ride' in new_log: #process strings with Ride info\n",
    "                new_log = new_log.split(' mendoza v9: [INFO]: Ride - ')\n",
    "               \n",
    "                log_values = extract_values_from_log(new_log[1])\n",
    "\n",
    "                duration = int(float(log_values[0]))\n",
    "                resistance_list.append(int(log_values[1]))\n",
    "         \n",
    "\n",
    "            elif 'Telemetry' in new_log:\n",
    "                new_log = new_log.split(' mendoza v9: [INFO]: Telemetry - ')\n",
    "               \n",
    "                log_values = extract_values_from_log(new_log[1])\n",
    "\n",
    "                heart_rate_list.append(int(log_values[0]))\n",
    "                rpm_list.append(int(log_values[1]))\n",
    "                power_list.append(round(float(log_values[2]),3))\n",
    "\n",
    "\n",
    "        elif 'new ride' in log and first_user_collected: #New user is starting, so load collected data into snowflake\n",
    "            total_power = sum(power_list)\n",
    "            mean_power = mean(power_list)\n",
    "            mean_rpm = mean(rpm_list)\n",
    "            mean_heart_rate = mean(heart_rate_list)\n",
    "            mean_resistance = mean(resistance_list)\n",
    "\n",
    "            cs.execute(\n",
    "            \"\"\"INSERT INTO users(user_id, first_name, last_name, gender, date_of_birth, \n",
    "            height_cm, weight_kg, house_name, street, region, postcode, email, account_created) \"\"\"\n",
    "            \"VALUES(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\",\n",
    "            (\n",
    "            user_dictionary['user_id'],user_dictionary['first_name'],user_dictionary['last_name'],user_dictionary['gender'],\n",
    "            user_dictionary['date_of_birth'],user_dictionary['height_cm'],user_dictionary['weight_kg'],user_dictionary['house_number'],\n",
    "            user_dictionary['street_name'],user_dictionary['region'],user_dictionary['postcode'],\n",
    "            user_dictionary['email_address'],user_dictionary['account_create_date']\n",
    "            )\n",
    "            )\n",
    "            print('made insert into users')\n",
    "            \n",
    "            cs.execute(\n",
    "            \"INSERT INTO rides(user_id, begin_timestamp, total_duration_sec, total_power, mean_power, mean_resistance, mean_rpm, mean_heart_rate) \"\n",
    "            \"VALUES(%s,%s,%s,%s,%s,%s,%s,%s)\",\n",
    "            (user_dictionary['user_id'], begin_timestamp, duration, \n",
    "            total_power, mean_power, mean_resistance, \n",
    "            mean_rpm, mean_heart_rate)\n",
    "            \n",
    "            )\n",
    "            print('made insert into rides')\n",
    "            \n",
    "            \n",
    "                \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
